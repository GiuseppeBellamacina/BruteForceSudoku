{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from joblib import Parallel, delayed\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.cuda.amp import autocast, GradScaler\n",
    "import numpy as np\n",
    "from sudoku import Sudoku\n",
    "import tqdm\n",
    "import pygame\n",
    "import time\n",
    "from random import randint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SudokuDataset(Dataset):\n",
    "    def __init__(self, data):\n",
    "        self.puzzles = [torch.tensor(puzzle, dtype=torch.float).unsqueeze(0) for puzzle, _ in data]\n",
    "        self.solutions = [torch.tensor(solution, dtype=torch.long) for _, solution in data]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.puzzles)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.puzzles[idx], self.solutions[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def swap_rows(grid1, grid2):\n",
    "    \"\"\"Swap two random rows within the same block for both puzzle and solution.\"\"\"\n",
    "    block = np.random.randint(0, 3)\n",
    "    row1, row2 = np.random.choice(range(block * 3, (block + 1) * 3), size=2, replace=False)\n",
    "    grid1[[row1, row2]] = grid1[[row2, row1]]\n",
    "    grid2[[row1, row2]] = grid2[[row2, row1]]\n",
    "    return grid1, grid2\n",
    "\n",
    "def swap_columns(grid1, grid2):\n",
    "    \"\"\"Swap two random columns within the same block for both puzzle and solution.\"\"\"\n",
    "    block = np.random.randint(0, 3)\n",
    "    col1, col2 = np.random.choice(range(block * 3, (block + 1) * 3), size=2, replace=False)\n",
    "    grid1[:, [col1, col2]] = grid1[:, [col2, col1]]\n",
    "    grid2[:, [col1, col2]] = grid2[:, [col2, col1]]\n",
    "    return grid1, grid2\n",
    "\n",
    "def rotate_grid(grid1, grid2):\n",
    "    \"\"\"Rotate both puzzle and solution by 90, 180, or 270 degrees.\"\"\"\n",
    "    k = np.random.choice([1, 2, 3])\n",
    "    return np.rot90(grid1, k), np.rot90(grid2, k)\n",
    "\n",
    "def augment_grid(puzzle, solution):\n",
    "    \"\"\"Apply random transformations to both puzzle and solution.\"\"\"\n",
    "    transformations = [swap_rows, swap_columns, rotate_grid]\n",
    "    np.random.shuffle(transformations)\n",
    "    for transform in transformations:\n",
    "        puzzle, solution = transform(puzzle, solution)\n",
    "    return puzzle, solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_single_sudoku():\n",
    "    grid = Sudoku.from_dim(3)\n",
    "    solution = np.array(grid.grid, dtype=np.int8)\n",
    "    grid.remove_numbers(randint(10, 55))\n",
    "    puzzle = np.array(grid.grid, dtype=np.int8)\n",
    "    return puzzle, solution\n",
    "\n",
    "def generate_dataset(num_samples, n_jobs=4):\n",
    "    data = Parallel(n_jobs=n_jobs)(\n",
    "        delayed(generate_single_sudoku)() for _ in tqdm.tqdm(range(num_samples))\n",
    "    )\n",
    "    puzzles, solutions = zip(*data)\n",
    "    \n",
    "    # Applichiamo data augmentation in modo consistente a puzzle e soluzione\n",
    "    augmented_data = []\n",
    "    for puzzle, solution in tqdm.tqdm(zip(puzzles, solutions), total=len(puzzles)):\n",
    "        puzzle_aug, solution_aug = augment_grid(puzzle, solution)\n",
    "        augmented_data.append((puzzle_aug, solution_aug))\n",
    "    \n",
    "    all_puzzles = np.concatenate((puzzles, [p[0] for p in augmented_data]))\n",
    "    all_solutions = np.concatenate((solutions, [p[1] for p in augmented_data]))\n",
    "    \n",
    "    return list(zip(all_puzzles, all_solutions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResidualBlock(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, kernel_size=3):\n",
    "        super(ResidualBlock, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels, out_channels, kernel_size=kernel_size, padding=1)\n",
    "        self.batch_norm1 = nn.BatchNorm2d(out_channels)\n",
    "        self.conv2 = nn.Conv2d(out_channels, out_channels, kernel_size=kernel_size, padding=1)\n",
    "        self.batch_norm2 = nn.BatchNorm2d(out_channels)\n",
    "        self.shortcut = nn.Sequential()\n",
    "        if in_channels != out_channels:\n",
    "            self.shortcut = nn.Sequential(\n",
    "                nn.Conv2d(in_channels, out_channels, kernel_size=1),\n",
    "                nn.BatchNorm2d(out_channels)\n",
    "            )\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = torch.relu(self.batch_norm1(self.conv1(x)))\n",
    "        out = self.batch_norm2(self.conv2(out))\n",
    "        out += self.shortcut(x)\n",
    "        out = torch.relu(out)\n",
    "        return out\n",
    "\n",
    "class PositionalEncoding(nn.Module):\n",
    "    def __init__(self, d_model, max_len=81):\n",
    "        super(PositionalEncoding, self).__init__()\n",
    "        pe = torch.zeros(max_len, d_model)\n",
    "        position = torch.arange(0, max_len, dtype=torch.float).unsqueeze(1)\n",
    "        div_term = torch.exp(torch.arange(0, d_model, 2).float() * (-torch.log(torch.tensor(10000.0)) / d_model))\n",
    "        pe[:, 0::2] = torch.sin(position * div_term)\n",
    "        pe[:, 1::2] = torch.cos(position * div_term)\n",
    "        pe = pe.unsqueeze(0)  # Forma (1, max_len, d_model)\n",
    "        self.register_buffer('pe', pe)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Espandi self.pe lungo la dimensione batch per poter essere sommato a x\n",
    "        pe_expanded = self.pe[:, :x.size(1), :].expand(x.size(0), -1, -1)  # Espande pe a (batch_size, 81, 256)\n",
    "        return x + pe_expanded.to(x.device)  # Somma con x\n",
    "\n",
    "class SudokuNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SudokuNet, self).__init__()\n",
    "\n",
    "        # Layer Convoluzionali con Residual Blocks\n",
    "        self.layer1 = ResidualBlock(1, 64)\n",
    "        self.layer2 = ResidualBlock(64, 128)\n",
    "        self.layer3 = ResidualBlock(128, 256)\n",
    "        self.layer4 = ResidualBlock(256, 256)\n",
    "\n",
    "        # Global Average Pooling\n",
    "        self.global_avg_pool = nn.AdaptiveAvgPool2d((9, 9))  # Restituisce (batch_size, 256, 9, 9)\n",
    "\n",
    "        # Modulo LSTM\n",
    "        self.lstm = nn.LSTM(input_size=256, hidden_size=512, num_layers=2, batch_first=True, dropout=0.3)\n",
    "\n",
    "        # Positional Encoding\n",
    "        self.positional_encoding = PositionalEncoding(d_model=256)  # d_model corrisponde al numero di canali\n",
    "\n",
    "        # Meccanismo di Attenzione\n",
    "        self.attention = nn.Linear(512, 1)\n",
    "\n",
    "        # Fully connected layer finale\n",
    "        self.fc1 = nn.Linear(512, 9 * 9 * 9)\n",
    "        self.dropout = nn.Dropout(p=0.3)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Passaggio attraverso i blocchi residuali\n",
    "        x = self.layer1(x)\n",
    "        x = self.layer2(x)\n",
    "        x = self.layer3(x)\n",
    "        x = self.layer4(x)\n",
    "\n",
    "        # Global Average Pooling\n",
    "        x = self.global_avg_pool(x)  # (batch_size, 256, 9, 9)\n",
    "\n",
    "        # Appiattisce a (batch_size, 81, 256)\n",
    "        x = x.permute(0, 2, 3, 1).view(x.size(0), 81, 256)\n",
    "\n",
    "        # Aggiungi Positional Encoding: deve essere applicato sulla dimensione 81, che rappresenta le celle\n",
    "        x = self.positional_encoding(x)\n",
    "\n",
    "        # Passaggio attraverso l'LSTM\n",
    "        x, _ = self.lstm(x)  # output LSTM, la sequenza è di lunghezza 81 con 512 unità nascoste\n",
    "\n",
    "        # Attenzione\n",
    "        attn_weights = torch.softmax(self.attention(x), dim=1)\n",
    "        x = torch.sum(attn_weights * x, dim=1)\n",
    "\n",
    "        # Passaggio attraverso il fully connected layer\n",
    "        x = self.dropout(x)\n",
    "        x = self.fc1(x)\n",
    "\n",
    "        # Output reshape in (batch_size, 9, 9, 9) per la previsione del Sudoku\n",
    "        return x.view(-1, 9, 9, 9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = generate_dataset(num_samples=100000, n_jobs=8)\n",
    "test_data = generate_dataset(num_samples=10, n_jobs=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(data), len(test_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = SudokuDataset(data)\n",
    "dataloader = DataLoader(dataset, batch_size=256, shuffle=True, pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset = SudokuDataset(test_data)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=256, shuffle=False, pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SudokuNet().to('cuda')\n",
    "criterion = nn.CrossEntropyLoss(ignore_index=-1).to('cuda')\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001, weight_decay=1e-5)\n",
    "scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=6, gamma=0.5)\n",
    "scaler = GradScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate(model, dataloader):\n",
    "    model.eval()\n",
    "    total_correct = 0\n",
    "    total_numbers = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for puzzles, solutions in dataloader:\n",
    "            puzzles, solutions = puzzles.to('cuda'), solutions.to('cuda')\n",
    "            output = model(puzzles)\n",
    "            output = output.view(-1, 9) \n",
    "            _, predicted = torch.max(output, 1)\n",
    "            \n",
    "            predicted = predicted.view(puzzles.size(0), 9, 9) + 1\n",
    "            solutions = solutions.view(puzzles.size(0), 9, 9)\n",
    "            \n",
    "            correct = (predicted == solutions).sum().item()\n",
    "            total_correct += correct\n",
    "            total_numbers += puzzles.size(0) * 81\n",
    "    \n",
    "    accuracy = total_correct / total_numbers\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def earlyStopping(val_losses, patience, delta, num_epochs):\n",
    "    count = patience\n",
    "    if len(val_losses) < patience: # se non abbiamo ancora abbastanza epoche per fare confronti\n",
    "        return False\n",
    "    elif len(val_losses) == num_epochs - 1: # se siamo all'ultima epoca\n",
    "        return False\n",
    "    else:\n",
    "        last_losses_sum = sum(val_losses[-patience:])\n",
    "        last_losses_avg = last_losses_sum / patience\n",
    "        for i in range(1, patience+1):\n",
    "            if val_losses[-i] < last_losses_avg + delta/2 and val_losses[-i] > last_losses_avg - delta/2:\n",
    "                count -= 1\n",
    "    return count <= 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_losses = []\n",
    "accuracies = []\n",
    "\n",
    "num_epochs = 20\n",
    "for epoch in tqdm.tqdm(range(num_epochs), desc=\"Training\", leave=False):\n",
    "    model.train()\n",
    "    losses = []\n",
    "    for inputs, targets in dataloader:\n",
    "        inputs = inputs.to('cuda')\n",
    "        targets = targets.to('cuda')\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        with autocast():\n",
    "            outputs = model(inputs)\n",
    "            outputs = outputs.view(-1, 9)\n",
    "            targets = targets.view(-1) - 1\n",
    "            loss = criterion(outputs, targets)\n",
    "            \n",
    "        losses.append(loss.item())\n",
    "        scaler.scale(loss).backward()\n",
    "        scaler.step(optimizer)\n",
    "        scaler.update()\n",
    "        \n",
    "    scheduler.step()\n",
    "    avg_losses.append(sum(losses) / len(losses))\n",
    "    accuracy = validate(model, dataloader)\n",
    "    accuracies.append(accuracy)\n",
    "    print(f'Epoch {epoch+1}/{num_epochs}, Loss: {avg_losses[-1]:.3f}, Validation Accuracy: {accuracy:.3f}')\n",
    "    if earlyStopping(avg_losses, 5, 0.005, num_epochs) or accuracy > 0.99:\n",
    "        print(\"Early stopping with accuracy: \", accuracy * 100, \"%\")\n",
    "        pygame.mixer.init()\n",
    "        for i in range(3):\n",
    "            pygame.mixer.Sound(\"msg.mp3\").play()\n",
    "            time.sleep(2.5)\n",
    "        pygame.mixer.quit()\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), 'model.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plot_values = [avg_losses, accuracies]\n",
    "plot_labels = ['Loss', 'Accuracy']\n",
    "\n",
    "\n",
    "def plot_data(data, labels):\n",
    "    subplots, ax = plt.subplots(1, len(data), figsize=(14, 7))\n",
    "    # Loss\n",
    "    ax[0].plot(data[0], '-r')\n",
    "    ax[0].set_xlabel('Epoch')\n",
    "    ax[0].set_ylabel(labels[0])\n",
    "    ax[0].set_title(labels[0])\n",
    "    # Accuracy\n",
    "    ax[1].plot(data[1], '-b')\n",
    "    ax[1].set_xlabel('Epoch')\n",
    "    ax[1].set_ylabel(labels[1])\n",
    "    ax[1].set_title(labels[1])\n",
    "\n",
    "plot_data(plot_values, plot_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test\n",
    "model.eval()\n",
    "count = 0\n",
    "total = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for i, (inputs, targets) in enumerate(test_dataloader):\n",
    "        inputs = inputs.to('cuda')\n",
    "        targets = targets.to('cuda')\n",
    "        outputs = model(inputs)\n",
    "        _, predicted = torch.max(outputs, 3)\n",
    "        predicted = predicted + 1\n",
    "        for j in range(inputs.size(0)):\n",
    "            puzzle = inputs[j].cpu().numpy().reshape(9, 9).astype(int)\n",
    "            solution = targets[j].cpu().numpy().reshape(9, 9).astype(int)\n",
    "            prediction = predicted[j].cpu().numpy().reshape(9, 9).astype(int)\n",
    "            incorrect = (prediction != solution)\n",
    "            num_incorrect = np.sum(incorrect)\n",
    "            if num_incorrect > 0:\n",
    "                count += 1\n",
    "                print(f'Puzzle {j + i * inputs.size(0)}:')\n",
    "                print('Input Puzzle:')\n",
    "                print(puzzle)\n",
    "                print('Predicted Solution:')\n",
    "                print(prediction)\n",
    "                print('Correct Solution:')\n",
    "                print(solution)\n",
    "                print(f'Number of incorrect cells: {num_incorrect}')\n",
    "                print('-' * 30)\n",
    "            total += 1\n",
    "\n",
    "print(count)\n",
    "print(total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data2 = generate_dataset(num_samples=512, n_jobs=8)\n",
    "test_dataset2 = SudokuDataset(test_data2)\n",
    "test_dataloader2 = DataLoader(test_dataset2, batch_size=256, shuffle=False, pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test\n",
    "model.eval()\n",
    "count = 0\n",
    "total = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for i, (inputs, targets) in enumerate(test_dataloader2):\n",
    "        inputs = inputs.to('cuda')\n",
    "        targets = targets.to('cuda')\n",
    "        outputs = model(inputs)\n",
    "        _, predicted = torch.max(outputs, 3)\n",
    "        predicted = predicted + 1\n",
    "        for j in range(inputs.size(0)):\n",
    "            puzzle = inputs[j].cpu().numpy().reshape(9, 9).astype(int)\n",
    "            solution = targets[j].cpu().numpy().reshape(9, 9).astype(int)\n",
    "            prediction = predicted[j].cpu().numpy().reshape(9, 9).astype(int)\n",
    "            incorrect = (prediction != solution)\n",
    "            num_incorrect = np.sum(incorrect)\n",
    "            if num_incorrect > 0:\n",
    "                count += 1\n",
    "                print(f'Puzzle {j + i * inputs.size(0)}:')\n",
    "                print('Input Puzzle:')\n",
    "                print(puzzle)\n",
    "                print('Predicted Solution:')\n",
    "                print(prediction)\n",
    "                print('Correct Solution:')\n",
    "                print(solution)\n",
    "                print(f'Number of incorrect cells: {num_incorrect}')\n",
    "                print('-' * 30)\n",
    "            total += 1\n",
    "\n",
    "print(count)\n",
    "print(total)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
